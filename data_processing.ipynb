{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c154c3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c200ee",
   "metadata": {},
   "source": [
    "# Contents\n",
    "- Download datasets\n",
    "- Data cleaning\n",
    "    - Check labels contain only 0/1\n",
    "    - Remove duplicates\n",
    "    - Check number of NaN/empty cells\n",
    "    - Remove / Normalize\n",
    "        - HTML tags\n",
    "        - links\n",
    "        - URL\n",
    "        - phone numbers\n",
    "        - emojis using Emojis library\n",
    "        - special unicode characters\n",
    "        - repeated occurences of punctuations and whitespaces\n",
    "        - short examples, where number of characters is smaller than 10\n",
    "    - lowercase characters to decrease token library size\n",
    "- Download cleaned dataframes as csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9961e327",
   "metadata": {},
   "source": [
    "## Download datasets\n",
    "- Reddit combi\n",
    "- Reddit title\n",
    "- Twitter full\n",
    "- Twitter non-advert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bcc12e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_combi_df = pd.read_csv(\n",
    "    \"data/Reddit_Combi.csv\",\n",
    "    sep=';',    \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5834d757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows:  3123\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>Body_Title</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Envy to other is swallowing me</td>\n",
       "      <td>Im from developingcountry, Indonesia , and for...</td>\n",
       "      <td>Envy to other is swallowing me Im from develop...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nothin outta the ordinary. Paradise. Job stres...</td>\n",
       "      <td>Um hello ....well many can relate im sure. Aft...</td>\n",
       "      <td>Nothin outta the ordinary. Paradise. Job stres...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Almost 49 and the chasm of emptiness has never...</td>\n",
       "      <td>I’ve been diagnosed severe bi polar where you ...</td>\n",
       "      <td>Almost 49 and the chasm of emptiness has never...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I’m happy again</td>\n",
       "      <td>After my closest friend left me in April, I ha...</td>\n",
       "      <td>I’m happy again After my closest friend left m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is it possible to recover from such a traumati...</td>\n",
       "      <td>I am only 15, and yet I feel my life is alread...</td>\n",
       "      <td>Is it possible to recover from such a traumati...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                     Envy to other is swallowing me   \n",
       "1  Nothin outta the ordinary. Paradise. Job stres...   \n",
       "2  Almost 49 and the chasm of emptiness has never...   \n",
       "3                                    I’m happy again   \n",
       "4  Is it possible to recover from such a traumati...   \n",
       "\n",
       "                                                body  \\\n",
       "0  Im from developingcountry, Indonesia , and for...   \n",
       "1  Um hello ....well many can relate im sure. Aft...   \n",
       "2  I’ve been diagnosed severe bi polar where you ...   \n",
       "3  After my closest friend left me in April, I ha...   \n",
       "4  I am only 15, and yet I feel my life is alread...   \n",
       "\n",
       "                                          Body_Title  label  \n",
       "0  Envy to other is swallowing me Im from develop...      1  \n",
       "1  Nothin outta the ordinary. Paradise. Job stres...      1  \n",
       "2  Almost 49 and the chasm of emptiness has never...      1  \n",
       "3  I’m happy again After my closest friend left m...      0  \n",
       "4  Is it possible to recover from such a traumati...      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of rows: \", len(reddit_combi_df))\n",
    "reddit_combi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bbce141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3123.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.878963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.326223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             label\n",
       "count  3123.000000\n",
       "mean      0.878963\n",
       "std       0.326223\n",
       "min       0.000000\n",
       "25%       1.000000\n",
       "50%       1.000000\n",
       "75%       1.000000\n",
       "max       1.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_combi_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8522746a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_title_df = pd.read_csv(    \n",
    "    \"data/Reddit_Title.csv\",    \n",
    "    sep=';',    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3211c6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows:  5556\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My aunt and uncle scoring their first gig as p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How do I stop stressing about work when I'm at...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Meeting a fellow suicidal student in middle sc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My brain feels literally numb. Is this depress...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A mother's reaction after seeing her son has p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  label\n",
       "0  My aunt and uncle scoring their first gig as p...      0\n",
       "1  How do I stop stressing about work when I'm at...      1\n",
       "2  Meeting a fellow suicidal student in middle sc...      1\n",
       "3  My brain feels literally numb. Is this depress...      1\n",
       "4  A mother's reaction after seeing her son has p...      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of rows: \", len(reddit_title_df))\n",
    "reddit_title_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6486af68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5556.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.49406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.50001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label\n",
       "count  5556.00000\n",
       "mean      0.49406\n",
       "std       0.50001\n",
       "min       0.00000\n",
       "25%       0.00000\n",
       "50%       0.00000\n",
       "75%       1.00000\n",
       "max       1.00000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_title_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e9f59a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_full_df = pd.read_csv(\n",
    "    \"data/Twitter_Full.csv\",\n",
    "    sep=';',    \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5186846d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows:  8900\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Being s mom is cleaning 24/7 the same shit ove...</td>\n",
       "      <td>['momlife', 'kids', 'tired']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>And now we have been given the walkthru book b...</td>\n",
       "      <td>['walkthru']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wishing YOU Peace Joy &amp; Love! JoyTrain MentalH...</td>\n",
       "      <td>['Peace', 'Joy', 'Love', 'JoyTrain', 'MentalHe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>speak-no-evil monkey Can I Be Honest With You...</td>\n",
       "      <td>['therapy', 'help', 'NLP', 'CBT', 'hypnotherap...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Psy Do u hv any regrets? Me No Psy Are you hap...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Being s mom is cleaning 24/7 the same shit ove...   \n",
       "1  And now we have been given the walkthru book b...   \n",
       "2  Wishing YOU Peace Joy & Love! JoyTrain MentalH...   \n",
       "3   speak-no-evil monkey Can I Be Honest With You...   \n",
       "4  Psy Do u hv any regrets? Me No Psy Are you hap...   \n",
       "\n",
       "                                            hashtags  labels  \n",
       "0                       ['momlife', 'kids', 'tired']       1  \n",
       "1                                       ['walkthru']       0  \n",
       "2  ['Peace', 'Joy', 'Love', 'JoyTrain', 'MentalHe...       0  \n",
       "3  ['therapy', 'help', 'NLP', 'CBT', 'hypnotherap...       1  \n",
       "4                                                 []       0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of rows: \", len(twitter_full_df))\n",
    "twitter_full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bebf2610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.509438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.499939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            labels\n",
       "count  8900.000000\n",
       "mean      0.509438\n",
       "std       0.499939\n",
       "min       0.000000\n",
       "25%       0.000000\n",
       "50%       1.000000\n",
       "75%       1.000000\n",
       "max       1.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_full_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c683ae0",
   "metadata": {},
   "source": [
    "Rename column labels to match other dataframes' label column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6fd8fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Being s mom is cleaning 24/7 the same shit ove...</td>\n",
       "      <td>['momlife', 'kids', 'tired']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>And now we have been given the walkthru book b...</td>\n",
       "      <td>['walkthru']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wishing YOU Peace Joy &amp; Love! JoyTrain MentalH...</td>\n",
       "      <td>['Peace', 'Joy', 'Love', 'JoyTrain', 'MentalHe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>speak-no-evil monkey Can I Be Honest With You...</td>\n",
       "      <td>['therapy', 'help', 'NLP', 'CBT', 'hypnotherap...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Psy Do u hv any regrets? Me No Psy Are you hap...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Being s mom is cleaning 24/7 the same shit ove...   \n",
       "1  And now we have been given the walkthru book b...   \n",
       "2  Wishing YOU Peace Joy & Love! JoyTrain MentalH...   \n",
       "3   speak-no-evil monkey Can I Be Honest With You...   \n",
       "4  Psy Do u hv any regrets? Me No Psy Are you hap...   \n",
       "\n",
       "                                            hashtags  label  \n",
       "0                       ['momlife', 'kids', 'tired']      1  \n",
       "1                                       ['walkthru']      0  \n",
       "2  ['Peace', 'Joy', 'Love', 'JoyTrain', 'MentalHe...      0  \n",
       "3  ['therapy', 'help', 'NLP', 'CBT', 'hypnotherap...      1  \n",
       "4                                                 []      0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_full_df = twitter_full_df.rename(columns={\"labels\": \"label\"})\n",
    "twitter_full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdec638e",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_non_advert = pd.read_csv(\n",
    "    \"data/Twitter_Non-Advert.csv\",\n",
    "    sep=';',    \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29aa8979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows:  2051\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>speak-no-evil monkey Can I Be Honest With You...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Frau Goebbels early signs of psychosis psychot...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A lot of work and unfulfilled tasks plunge you...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Private health insurance delivers value for yo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XpertOnline offers you the convenience of view...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0   speak-no-evil monkey Can I Be Honest With You...      1\n",
       "1  Frau Goebbels early signs of psychosis psychot...      1\n",
       "2  A lot of work and unfulfilled tasks plunge you...      1\n",
       "3  Private health insurance delivers value for yo...      1\n",
       "4  XpertOnline offers you the convenience of view...      1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of rows: \", len(twitter_non_advert))\n",
    "twitter_non_advert.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13638536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2051.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.618235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.485938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             label\n",
       "count  2051.000000\n",
       "mean      0.618235\n",
       "std       0.485938\n",
       "min       0.000000\n",
       "25%       0.000000\n",
       "50%       1.000000\n",
       "75%       1.000000\n",
       "max       1.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_non_advert.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "854bd184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all dataframes into list\n",
    "df_list = [reddit_combi_df, reddit_title_df, twitter_full_df, twitter_non_advert]\n",
    "df_names = [\"Reddit combi\", \"Reddit title\", \"Twitter full\", \"Twitter non advert\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b25efd5",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac29bc1",
   "metadata": {},
   "source": [
    "### Check that label column contains only 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab250f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit combi Number of invalid labels:  0 \n",
      "\n",
      "Reddit title Number of invalid labels:  0 \n",
      "\n",
      "Twitter full Number of invalid labels:  0 \n",
      "\n",
      "Twitter non advert Number of invalid labels:  0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df_list)):\n",
    "    count = (~np.isin(df_list[i]['label'], [0, 1])).sum()\n",
    "    print(df_names[i], \"Number of invalid labels: \", count, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e4025f",
   "metadata": {},
   "source": [
    "### Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00b8d92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit title had  24 duplicates\n",
      "Twitter full had  375 duplicates\n",
      "Twitter non advert had  79 duplicates\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df_list)):\n",
    "    old_len = len(df_list[i])\n",
    "    df_list[i] = df_list[i].drop_duplicates()\n",
    "    new_len = len(df_list[i])\n",
    "    if new_len < old_len:\n",
    "        print(df_names[i], \"had \", old_len - new_len, \"duplicates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac721e1",
   "metadata": {},
   "source": [
    "### Check number of rows containing NaN or are empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5a90406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit combi NaN or empty examples:  title         0\n",
      "body          7\n",
      "Body_Title    0\n",
      "label         0\n",
      "dtype: int64 \n",
      "\n",
      "Reddit title NaN or empty examples:  title    0\n",
      "label    0\n",
      "dtype: int64 \n",
      "\n",
      "Twitter full NaN or empty examples:  text        0\n",
      "hashtags    6\n",
      "label       0\n",
      "dtype: int64 \n",
      "\n",
      "Twitter non advert NaN or empty examples:  text     0\n",
      "label    0\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df_list)):\n",
    "    empty_or_nan = df_list[i].isnull() | df_list[i].apply(lambda col: col.astype(str).str.strip().eq(''))\n",
    "    count = empty_or_nan.sum()\n",
    "    print(df_names[i], \"NaN or empty examples: \", count, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c192be",
   "metadata": {},
   "source": [
    "Number of NaN or empty examples is low for Reddit combi and Twitter full and zero to others. Print rows containing NaN or empty column to see if they contain enough information to be condidered as a sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bdb23840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  title body  \\\n",
      "86    Dealing With A Stressful Situation When All Alone  NaN   \n",
      "215   Everyone must get off their screens and indulg...  NaN   \n",
      "518   In order to deal with stress, it's important t...  NaN   \n",
      "540   Recognizing your own self-worth exists outside...  NaN   \n",
      "847   My depression is giving me negative thoughts a...  NaN   \n",
      "1755  I got caught doing something wired by my sibli...  NaN   \n",
      "2557  Taking a Stab on defining \"Being Realistic vs ...  NaN   \n",
      "\n",
      "                                             Body_Title  label  \n",
      "86    Dealing With A Stressful Situation When All Al...      1  \n",
      "215   Everyone must get off their screens and indulg...      0  \n",
      "518   In order to deal with stress, it's important t...      1  \n",
      "540   Recognizing your own self-worth exists outside...      0  \n",
      "847   My depression is giving me negative thoughts a...      1  \n",
      "1755  I got caught doing something wired by my sibli...      1  \n",
      "2557  Taking a Stab on defining \"Being Realistic vs ...      0  \n"
     ]
    }
   ],
   "source": [
    "mask = reddit_combi_df.isnull() | reddit_combi_df.apply(lambda col: col.astype(str).str.strip().eq(''))\n",
    "rows_with_empty_or_nan = reddit_combi_df[mask.any(axis=1)]\n",
    "print(rows_with_empty_or_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f55971da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text hashtags  label\n",
      "663                   ['stress', 'studying', 'anxiety']      NaN      1\n",
      "1508                               nature world arbaz73      NaN      1\n",
      "2678                               nature world arbaz73      NaN      1\n",
      "4602  ['nature world arbaz73', 'arbaz 73', 'nature',...      NaN      0\n",
      "4607  DidYouKnow that laughing lowers levels of stre...      NaN      0\n",
      "4791                Is Your Stress Bothering You Today?      NaN      1\n",
      "7292  ['nature world arbaz73', 'arbaz 73', 'nature',...      NaN      0\n",
      "8757  ['DidYouKnow', 'laughing', 'stress', 'ImmuneSy...      NaN      0\n"
     ]
    }
   ],
   "source": [
    "mask = twitter_full_df.isnull() | twitter_full_df.apply(lambda col: col.astype(str).str.strip().eq(''))\n",
    "rows_with_empty_or_nan = twitter_full_df[mask.any(axis=1)]\n",
    "print(rows_with_empty_or_nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d4a0f3",
   "metadata": {},
   "source": [
    "The rows containing Nan have enough information, so keep those examples without modifying."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8362c17",
   "metadata": {},
   "source": [
    "## Remove/Normalize following \n",
    "- HTML tags\n",
    "- links\n",
    "- URL\n",
    "- phone numbers\n",
    "- emojis\n",
    "- special unicode characters\n",
    "- repeated occurences of punctuations and whitespaces\n",
    "- short examples, where number of characters is smaller than 10\n",
    "- lowercase characters to decrease token library size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0bcbca",
   "metadata": {},
   "source": [
    "### HTML tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c519d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit combi contains:  0 HTML tags\n",
      "\n",
      "Reddit title contains:  0 HTML tags\n",
      "\n",
      "Twitter full contains:  0 HTML tags\n",
      "\n",
      "Twitter non advert contains:  0 HTML tags\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# See how many rows contain HTML tag\n",
    "\n",
    "# HTML tag must start with < and end with > and have at least one character (not >) inside it\n",
    "html_tags = re.compile(r'<[^>]+>')\n",
    "for i in range(len(df_list)):\n",
    "    count = df_list[i].apply(lambda row: row.astype(str).str.contains(html_tags).any(), axis=1).sum()\n",
    "    print(df_names[i], \"contains: \", count, \"HTML tags\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a833963",
   "metadata": {},
   "source": [
    "No HTML tages to clear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e02378",
   "metadata": {},
   "source": [
    "### URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f39d3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit combi contains:  0 URLs\n",
      "\n",
      "Reddit title contains:  0 URLs\n",
      "\n",
      "Twitter full contains:  0 URLs\n",
      "\n",
      "Twitter non advert contains:  0 URLs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# See how many rows contain URLs\n",
    "\n",
    "# Assume URL must contain https:// or http://\n",
    "url = re.compile(r'https?://[^\\s\"]+')\n",
    "\n",
    "for i in range(len(df_list)):\n",
    "    count = df_list[i].apply(lambda row: row.astype(str).str.contains(url).any(), axis=1).sum()\n",
    "    print(df_names[i], \"contains: \", count, \"URLs\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25a9fc1",
   "metadata": {},
   "source": [
    "No URLs to remove"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac97d5ff",
   "metadata": {},
   "source": [
    "### Phone numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39208e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit combi contains:  0 phone numbers\n",
      "\n",
      "Reddit title contains:  0 phone numbers\n",
      "\n",
      "Twitter full contains:  0 phone numbers\n",
      "\n",
      "Twitter non advert contains:  0 phone numbers\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# See how many rows contain phone numbers\n",
    "\n",
    "# Regex is taken from: https://www.geeksforgeeks.org/dsa/validate-phone-numbers-with-country-code-extension-using-regular-expression/\n",
    "# edited it, so it doesn't require + at start \n",
    "\n",
    "phone = re.compile(r'^[+]?(?:[0-9\\-\\(\\)\\/\\.]\\s?){6,15}[0-9]$')\n",
    "\n",
    "for i in range(len(df_list)):\n",
    "    count = df_list[i].apply(lambda row: row.astype(str).str.contains(phone).any(), axis=1).sum()\n",
    "    print(df_names[i], \"contains: \", count, \"phone numbers\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27295398",
   "metadata": {},
   "source": [
    "No phone numbers to remove"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067c75dc",
   "metadata": {},
   "source": [
    "### Convert emojis using Emoji library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01b9b280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3502c421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit combi contains: 0 emojis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oonas\\AppData\\Local\\Temp\\ipykernel_34544\\1261649181.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_list[i][col] = df_list[i][col].map(lambda x: emoji.demojize(str(x)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit title contains: 0 emojis\n",
      "Twitter full contains: 6 emojis\n",
      "Twitter non advert contains: 0 emojis\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df_list)):\n",
    "    count = 0\n",
    "    for col in df_list[i].columns:\n",
    "        if col != \"label\":\n",
    "            count += df_list[i][col].map(lambda x: len(emoji.emoji_list(str(x)))).sum()\n",
    "            df_list[i][col] = df_list[i][col].map(lambda x: emoji.demojize(str(x)))\n",
    "    print(df_names[i], \"contains:\", count, \"emojis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db7f09c",
   "metadata": {},
   "source": [
    "### Special unicode characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85906185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit combi contains:  63 special unicode characters\n",
      "\n",
      "Reddit title contains:  0 special unicode characters\n",
      "\n",
      "Twitter full contains:  43 special unicode characters\n",
      "\n",
      "Twitter non advert contains:  6 special unicode characters\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# See how many rows contain special unicde characters\n",
    "\n",
    "# find non-ascii characters and non-emoji \n",
    "special = re.compile(r'[\\u200a\\u200b\\u202f\\u2060\\u2063\\u2066\\u2069\\ufeff]')\n",
    "\n",
    "for i in range(len(df_list)):\n",
    "    count = df_list[i].apply(lambda row: row.astype(str).str.contains(special).any(), axis=1).sum()\n",
    "    print(df_names[i], \"contains: \", count, \"special unicode characters\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc525e7c",
   "metadata": {},
   "source": [
    "There are quite many special unicode characters. Next, see what they look like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50a868f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit combi: 298 special unicode characters (excluding emojis)\n",
      "Reddit title: 0 special unicode characters (excluding emojis)\n",
      "Twitter full: 146 special unicode characters (excluding emojis)\n",
      "Twitter non advert: 9 special unicode characters (excluding emojis)\n",
      "\n",
      "Reddit combi unique special characters:\n",
      "{'\\u200b', '\\ufeff'}\n",
      "\n",
      "Reddit title unique special characters:\n",
      "set()\n",
      "\n",
      "Twitter full unique special characters:\n",
      "{'\\u200b', '\\u2060', '\\u2063', '\\u202f', '\\u2066', '\\u2069', '\\u200a'}\n",
      "\n",
      "Twitter non advert unique special characters:\n",
      "{'\\u2060', '\\u2063', '\\u202f', '\\u2066', '\\u2069'}\n"
     ]
    }
   ],
   "source": [
    "special_cases = {}\n",
    "for i in range(len(df_list)):\n",
    "    \n",
    "    # see special characters\n",
    "    row_special_chars = []\n",
    "    for row in df_list[i].astype(str).itertuples(index=False):\n",
    "        for cell in row:\n",
    "            matches = special.findall(cell)\n",
    "            row_special_chars.extend(matches)\n",
    "\n",
    "    special_cases[df_names[i]] = row_special_chars\n",
    "    print(f\"{df_names[i]}: {len(row_special_chars)} special unicode characters (excluding emojis)\")\n",
    "\n",
    "    # Remove special chars\n",
    "    df_list[i] = df_list[i].map(lambda x: special.sub('', str(x)))\n",
    "\n",
    "for name, chars in special_cases.items():\n",
    "    print(f\"\\n{name} unique special characters:\")\n",
    "    print(set(chars))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c54bd4d",
   "metadata": {},
   "source": [
    "### Repeated occurences of punctuations and whitespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e29d6f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit combi contains:  615 special unicode characters\n",
      "\n",
      "Reddit title contains:  327 special unicode characters\n",
      "\n",
      "Twitter full contains:  911 special unicode characters\n",
      "\n",
      "Twitter non advert contains:  224 special unicode characters\n",
      "\n",
      "Reddit combi contains:  3123 whitespaces\n",
      "\n",
      "Reddit title contains:  5466 whitespaces\n",
      "\n",
      "Twitter full contains:  8525 whitespaces\n",
      "\n",
      "Twitter non advert contains:  1972 whitespaces\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# See how many\n",
    "\n",
    "import warnings\n",
    "# punctuations include more than one character of !, ? ., , :, ; in a row\n",
    "punc = re.compile(r'([!?.,:;])\\1+')\n",
    "\n",
    "# whitespaces include all whitespaces\n",
    "whitespace = re.compile(r'\\s+')\n",
    "\n",
    "# ignore unexpected warning\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    for i in range(len(df_list)):\n",
    "        count = df_list[i].apply(lambda row: row.astype(str).str.contains(punc).any(), axis=1).sum()\n",
    "        print(df_names[i], \"contains: \", count, \"special unicode characters\\n\")\n",
    "\n",
    "for i in range(len(df_list)):\n",
    "    count = df_list[i].apply(lambda row: row.astype(str).str.contains(whitespace).any(), axis=1).sum()\n",
    "    print(df_names[i], \"contains: \", count, \"whitespaces\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "356b52e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit combi: 2684 punctuations\n",
      "Reddit combi: 1088513 whitespaces\n",
      "Reddit title: 370 punctuations\n",
      "Reddit title: 93369 whitespaces\n",
      "Twitter full: 1116 punctuations\n",
      "Twitter full: 259526 whitespaces\n",
      "Twitter non advert: 255 punctuations\n",
      "Twitter non advert: 49671 whitespaces\n",
      "\n",
      "Reddit combi punctuations:\n",
      "{',', '!', '?', '.'}\n",
      "\n",
      "Reddit title punctuations:\n",
      "{'!', '?', '.'}\n",
      "\n",
      "Twitter full punctuations:\n",
      "{',', '!', '?', '.'}\n",
      "\n",
      "Twitter non advert punctuations:\n",
      "{',', '!', '?', '.'}\n",
      "\n",
      "Reddit combi whitespaces:\n",
      "{'  ', '\\t\\t ', ' ', '   ', '\\xa0 ', '\\xa0 \\xa0 ', ' \\xa0', '\\xa0', '\\xa0\\xa0 ', '    '}\n",
      "\n",
      "Reddit title whitespaces:\n",
      "{' '}\n",
      "\n",
      "Twitter full whitespaces:\n",
      "{'  ', ' ', ' \\xa0', '\\xa0 ', '\\xa0 \\xa0 ', '\\xa0\\xa0', '   ', '\\xa0\\xa0\\xa0 ', ' \\xa0 ', '\\xa0', '\\xa0\\xa0 ', '    '}\n",
      "\n",
      "Twitter non advert whitespaces:\n",
      "{'  ', ' ', '   ', '\\xa0 ', '\\xa0 \\xa0 ', ' \\xa0 ', '\\xa0', ' \\xa0'}\n"
     ]
    }
   ],
   "source": [
    "# Find all punctuation and whitespace characters\n",
    "punc_d = {}\n",
    "white = {}\n",
    "for i in range(len(df_list)):\n",
    "    \n",
    "    row_punc = []\n",
    "    row_white = []\n",
    "    for row in df_list[i].astype(str).itertuples(index=False):\n",
    "        for cell in row:\n",
    "            matches = punc.findall(cell)\n",
    "            row_punc.extend(matches)\n",
    "\n",
    "            matches2 = whitespace.findall(cell)\n",
    "            row_white.extend(matches2)\n",
    "\n",
    "    punc_d[df_names[i]] = row_punc\n",
    "    print(f\"{df_names[i]}: {len(row_punc)} punctuations\")\n",
    "\n",
    "    white[df_names[i]] = row_white\n",
    "    print(f\"{df_names[i]}: {len(row_white)} whitespaces\")\n",
    "\n",
    "for name, chars in punc_d.items():\n",
    "    print(f\"\\n{name} punctuations:\")\n",
    "    print(set(chars))\n",
    "\n",
    "for name, chars in white.items():\n",
    "    print(f\"\\n{name} whitespaces:\")\n",
    "    print(set(chars))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0806e3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove those above\n",
    "\n",
    "for i in range(len(df_list)):\n",
    "    # convert many characters to one\n",
    "    df_list[i] = df_list[i].map(lambda x: punc.sub(r'\\1', str(x))) \n",
    "\n",
    "    # convert all whitespaces to ' '\n",
    "    df_list[i] = df_list[i].map(lambda x: whitespace.sub(' ', str(x)).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963b191f",
   "metadata": {},
   "source": [
    "Check that punctuations are removed, for example !! -> !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b4fd2dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'And now we have been given the walkthru book by and to base our whole school PD on! grinning face instructionalcoaching excited'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list[2].iloc[1, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e710a7",
   "metadata": {},
   "source": [
    "### Examples with small number of characters (< 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d01214f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit combi contains:  0 rows with under 10 characters\n",
      "\n",
      "Reddit title contains:  52 rows with under 10 characters\n",
      "\n",
      "Twitter full contains:  0 rows with under 10 characters\n",
      "\n",
      "Twitter non advert contains:  0 rows with under 10 characters\n",
      "\n"
     ]
    }
   ],
   "source": [
    "threshold = 10\n",
    "\n",
    "for i in range(len(df_list)):\n",
    "    count = df_list[i].apply(lambda row: len(\" \".join(row.astype(str))) < threshold, axis=1).sum()\n",
    "    print(df_names[i], \"contains: \", count, \"rows with under 10 characters\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40400c5",
   "metadata": {},
   "source": [
    "Check are the 61 rows in Reddit title enough informaive to keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f8038f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title    Past\n",
      "label       1\n",
      "Name: 130, dtype: object\n",
      "title    Done\n",
      "label       1\n",
      "Name: 165, dtype: object\n",
      "title    Advice\n",
      "label         1\n",
      "Name: 310, dtype: object\n",
      "title    CTE?\n",
      "label       1\n",
      "Name: 407, dtype: object\n",
      "title    Leaving\n",
      "label          1\n",
      "Name: 466, dtype: object\n",
      "title    Help?\n",
      "label        1\n",
      "Name: 560, dtype: object\n",
      "title    Whyyyyy\n",
      "label          1\n",
      "Name: 589, dtype: object\n",
      "title    Hi\n",
      "label     1\n",
      "Name: 593, dtype: object\n",
      "title    I can't\n",
      "label          1\n",
      "Name: 598, dtype: object\n",
      "title    lonely\n",
      "label         1\n",
      "Name: 648, dtype: object\n",
      "title    Alone\n",
      "label        1\n",
      "Name: 674, dtype: object\n",
      "title    My day.\n",
      "label          1\n",
      "Name: 794, dtype: object\n",
      "title    b\n",
      "label    1\n",
      "Name: 854, dtype: object\n",
      "title    Anyone\n",
      "label         1\n",
      "Name: 996, dtype: object\n",
      "title    idk\n",
      "label      1\n",
      "Name: 1181, dtype: object\n",
      "title    Test\n",
      "label       1\n",
      "Name: 1454, dtype: object\n",
      "title    fuck\n",
      "label       1\n",
      "Name: 1558, dtype: object\n",
      "title    School\n",
      "label         1\n",
      "Name: 1730, dtype: object\n",
      "title    sigh\n",
      "label       1\n",
      "Name: 1761, dtype: object\n",
      "title    …….\n",
      "label      1\n",
      "Name: 1883, dtype: object\n",
      "title    You win\n",
      "label          1\n",
      "Name: 1959, dtype: object\n",
      "title    Balance\n",
      "label          1\n",
      "Name: 2002, dtype: object\n",
      "title    loss\n",
      "label       1\n",
      "Name: 2135, dtype: object\n",
      "title    Im done\n",
      "label          1\n",
      "Name: 2274, dtype: object\n",
      "title    21\n",
      "label     1\n",
      "Name: 2476, dtype: object\n",
      "title    hurt\n",
      "label       1\n",
      "Name: 2537, dtype: object\n",
      "title    Stress\n",
      "label         1\n",
      "Name: 2749, dtype: object\n",
      "title    broken\n",
      "label         1\n",
      "Name: 2891, dtype: object\n",
      "title    Afraid.\n",
      "label          1\n",
      "Name: 3075, dtype: object\n",
      "title    Burnout\n",
      "label          1\n",
      "Name: 3183, dtype: object\n",
      "title    Idk man\n",
      "label          1\n",
      "Name: 3275, dtype: object\n",
      "title    Help\n",
      "label       1\n",
      "Name: 3294, dtype: object\n",
      "title    venting\n",
      "label          1\n",
      "Name: 3346, dtype: object\n",
      "title    Shame\n",
      "label        1\n",
      "Name: 3470, dtype: object\n",
      "title    1\n",
      "label    1\n",
      "Name: 3527, dtype: object\n",
      "title    Help me\n",
      "label          1\n",
      "Name: 3574, dtype: object\n",
      "title    Why?\n",
      "label       1\n",
      "Name: 3589, dtype: object\n",
      "title    I’m out\n",
      "label          1\n",
      "Name: 3632, dtype: object\n",
      "title    college\n",
      "label          1\n",
      "Name: 3718, dtype: object\n",
      "title    help me\n",
      "label          1\n",
      "Name: 3798, dtype: object\n",
      "title    Oh man\n",
      "label         1\n",
      "Name: 4098, dtype: object\n",
      "title    friends\n",
      "label          1\n",
      "Name: 4182, dtype: object\n",
      "title    Money\n",
      "label        1\n",
      "Name: 4288, dtype: object\n",
      "title    A hug\n",
      "label        1\n",
      "Name: 4397, dtype: object\n",
      "title    Tired\n",
      "label        1\n",
      "Name: 4428, dtype: object\n",
      "title    Low\n",
      "label      1\n",
      "Name: 4786, dtype: object\n",
      "title    Poop\n",
      "label       1\n",
      "Name: 4795, dtype: object\n",
      "title    Ouch.\n",
      "label        1\n",
      "Name: 4995, dtype: object\n",
      "title    Teacher\n",
      "label          1\n",
      "Name: 5160, dtype: object\n",
      "title    I\n",
      "label    1\n",
      "Name: 5200, dtype: object\n",
      "title    Lone\n",
      "label       1\n",
      "Name: 5315, dtype: object\n",
      "title    Rocking\n",
      "label          1\n",
      "Name: 5334, dtype: object\n"
     ]
    }
   ],
   "source": [
    "rows_to_drop = []\n",
    "for idx, row in df_list[1].iterrows():\n",
    "    row_text = \" \".join(str(x) for x in row)  \n",
    "    if len(row_text) < threshold:\n",
    "        print(row)\n",
    "        rows_to_drop.append(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab117f9",
   "metadata": {},
   "source": [
    "The above examples are quite non-informative. Remove those from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "68987fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5480"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list[1] = df_list[1].drop(rows_to_drop)\n",
    "len(df_list[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc3bfac",
   "metadata": {},
   "source": [
    "### Lowercase characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d25ec346",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_list)):\n",
    "    for col in df_list[i].columns:\n",
    "        if col != \"label\":  \n",
    "            df_list[i][col] = df_list[i][col].map(lambda x: str(x).lower())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec990b74",
   "metadata": {},
   "source": [
    "## Save cleaned dataframes as csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad939124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndf_list[0].to_csv('Reddit_Combi_cleaned.csv', index=False)\\ndf_list[1].to_csv('Reddit_Title_cleaned.csv', index=False)\\ndf_list[2].to_csv('Twitter_Full_cleaned.csv', index=False)\\ndf_list[3].to_csv('Twitter_Non-Advert_cleaned.csv', index=False)\\n\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_list[0].to_csv('Reddit_Combi_cleaned.csv', index=False)\n",
    "df_list[1].to_csv('Reddit_Title_cleaned.csv', index=False)\n",
    "df_list[2].to_csv('Twitter_Full_cleaned.csv', index=False)\n",
    "df_list[3].to_csv('Twitter_Non-Advert_cleaned.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
